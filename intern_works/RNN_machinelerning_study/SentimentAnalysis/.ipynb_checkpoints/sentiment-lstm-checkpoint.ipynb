{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 感情分析をRNNでやってみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yamaguchishota/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./reviews.txt', 'r') as f:\n",
    "    reviews = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./labels.txt','r') as f:\n",
    "    labels = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npositive\\nnegative\\npo'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
    "reviews = all_text.split('\\n')\n",
    "\n",
    "all_text = ' '.join(reviews)\n",
    "words = all_text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int = {word:ii for ii,word in enumerate(vocab,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = []\n",
    "for each in reviews:\n",
    "    reviews_int.append([vocab_to_int[word] for word in each.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_int レビューを数字の配列に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルをベクトルにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.split('\\n')\n",
    "labels = np.array([1 if each =='positive' else 0 for each in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_lens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(review_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_idx = [ii for ii, review in enumerate(reviews_int) if len(review) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_int[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_int = [reviews_int[ii] for ii in non_zero_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([labels[ii] for ii in non_zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 200\n",
    "features = np.zeros((len(reviews_int), seq_len), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in enumerate(reviews_int):\n",
    "    features[i, -len(row):] = np.array(row)[:seq_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features[:10,:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをトレーニング用と検証用に分割する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(len(features)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = features[:split_idx], features[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, val_y = labels[:split_idx], labels[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = int(len(val_x)*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x, test_x = val_x[:test_idx], val_x[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y, test_y = val_y[:test_idx], val_y[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: \t\t(20000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set: \\t\\t{}\".format(train_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set: \t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set: \\t{}\".format(val_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: \t\t(2500, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グラフの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 256\n",
    "lstm_layers = 1\n",
    "batch_size = 500\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(vocab_to_int) + 1\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.int32,[None,None], name='inputs')\n",
    "    labels_ = tf.placeholder(tf.int32,[None,None], name='labels')\n",
    "    keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "\n",
    "with graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_words,embed_size),-1,1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMセルとレイヤーを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell,embed,initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推定値の計算と損失関数、最適化処理の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[:,-1],1,activation_fn=tf.sigmoid)\n",
    "    cost = tf.losses.mean_squared_error(labels_,predictions)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習精度の計測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ（指定長のデータ）を返すモジュール定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, y, batch_size=100):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## トレーニング（学習）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 Iteration: 5 Training Loss: 0.243\n",
      "Epoch: 0/10 Iteration: 10 Training Loss: 0.241\n",
      "Epoch: 0/10 Iteration: 15 Training Loss: 0.216\n",
      "Epoch: 0/10 Iteration: 20 Training Loss: 0.235\n",
      "Epoch: 0/10 Iteration: 25 Training Loss: 0.223\n",
      "Value Acc: 0.629\n",
      "Epoch: 0/10 Iteration: 30 Training Loss: 0.228\n",
      "Epoch: 0/10 Iteration: 35 Training Loss: 0.216\n",
      "Epoch: 0/10 Iteration: 40 Training Loss: 0.194\n",
      "Epoch: 1/10 Iteration: 45 Training Loss: 0.192\n",
      "Epoch: 1/10 Iteration: 50 Training Loss: 0.210\n",
      "Value Acc: 0.640\n",
      "Epoch: 1/10 Iteration: 55 Training Loss: 0.191\n",
      "Epoch: 1/10 Iteration: 60 Training Loss: 0.173\n",
      "Epoch: 1/10 Iteration: 65 Training Loss: 0.161\n",
      "Epoch: 1/10 Iteration: 70 Training Loss: 0.172\n",
      "Epoch: 1/10 Iteration: 75 Training Loss: 0.143\n",
      "Value Acc: 0.762\n",
      "Epoch: 1/10 Iteration: 80 Training Loss: 0.138\n",
      "Epoch: 2/10 Iteration: 85 Training Loss: 0.136\n",
      "Epoch: 2/10 Iteration: 90 Training Loss: 0.165\n",
      "Epoch: 2/10 Iteration: 95 Training Loss: 0.146\n",
      "Epoch: 2/10 Iteration: 100 Training Loss: 0.153\n",
      "Value Acc: 0.758\n",
      "Epoch: 2/10 Iteration: 105 Training Loss: 0.219\n",
      "Epoch: 2/10 Iteration: 110 Training Loss: 0.204\n",
      "Epoch: 2/10 Iteration: 115 Training Loss: 0.189\n",
      "Epoch: 2/10 Iteration: 120 Training Loss: 0.206\n",
      "Epoch: 3/10 Iteration: 125 Training Loss: 0.147\n",
      "Value Acc: 0.708\n",
      "Epoch: 3/10 Iteration: 130 Training Loss: 0.157\n",
      "Epoch: 3/10 Iteration: 135 Training Loss: 0.144\n",
      "Epoch: 3/10 Iteration: 140 Training Loss: 0.185\n",
      "Epoch: 3/10 Iteration: 145 Training Loss: 0.185\n",
      "Epoch: 3/10 Iteration: 150 Training Loss: 0.174\n",
      "Value Acc: 0.676\n",
      "Epoch: 3/10 Iteration: 155 Training Loss: 0.143\n",
      "Epoch: 3/10 Iteration: 160 Training Loss: 0.148\n",
      "Epoch: 4/10 Iteration: 165 Training Loss: 0.128\n",
      "Epoch: 4/10 Iteration: 170 Training Loss: 0.159\n",
      "Epoch: 4/10 Iteration: 175 Training Loss: 0.107\n",
      "Value Acc: 0.751\n",
      "Epoch: 4/10 Iteration: 180 Training Loss: 0.133\n",
      "Epoch: 4/10 Iteration: 185 Training Loss: 0.082\n",
      "Epoch: 4/10 Iteration: 190 Training Loss: 0.171\n",
      "Epoch: 4/10 Iteration: 195 Training Loss: 0.163\n",
      "Epoch: 4/10 Iteration: 200 Training Loss: 0.200\n",
      "Value Acc: 0.637\n",
      "Epoch: 5/10 Iteration: 205 Training Loss: 0.174\n",
      "Epoch: 5/10 Iteration: 210 Training Loss: 0.177\n",
      "Epoch: 5/10 Iteration: 215 Training Loss: 0.165\n",
      "Epoch: 5/10 Iteration: 220 Training Loss: 0.166\n",
      "Epoch: 5/10 Iteration: 225 Training Loss: 0.114\n",
      "Value Acc: 0.747\n",
      "Epoch: 5/10 Iteration: 230 Training Loss: 0.141\n",
      "Epoch: 5/10 Iteration: 235 Training Loss: 0.144\n",
      "Epoch: 5/10 Iteration: 240 Training Loss: 0.142\n",
      "Epoch: 6/10 Iteration: 245 Training Loss: 0.102\n",
      "Epoch: 6/10 Iteration: 250 Training Loss: 0.105\n",
      "Value Acc: 0.787\n",
      "Epoch: 6/10 Iteration: 255 Training Loss: 0.103\n",
      "Epoch: 6/10 Iteration: 260 Training Loss: 0.089\n",
      "Epoch: 6/10 Iteration: 265 Training Loss: 0.075\n",
      "Epoch: 6/10 Iteration: 270 Training Loss: 0.099\n",
      "Epoch: 6/10 Iteration: 275 Training Loss: 0.081\n",
      "Value Acc: 0.790\n",
      "Epoch: 6/10 Iteration: 280 Training Loss: 0.094\n",
      "Epoch: 7/10 Iteration: 285 Training Loss: 0.098\n",
      "Epoch: 7/10 Iteration: 290 Training Loss: 0.109\n",
      "Epoch: 7/10 Iteration: 295 Training Loss: 0.094\n",
      "Epoch: 7/10 Iteration: 300 Training Loss: 0.091\n",
      "Value Acc: 0.793\n",
      "Epoch: 7/10 Iteration: 305 Training Loss: 0.086\n",
      "Epoch: 7/10 Iteration: 310 Training Loss: 0.084\n",
      "Epoch: 7/10 Iteration: 315 Training Loss: 0.067\n",
      "Epoch: 7/10 Iteration: 320 Training Loss: 0.064\n",
      "Epoch: 8/10 Iteration: 325 Training Loss: 0.077\n",
      "Value Acc: 0.815\n",
      "Epoch: 8/10 Iteration: 330 Training Loss: 0.078\n",
      "Epoch: 8/10 Iteration: 335 Training Loss: 0.075\n",
      "Epoch: 8/10 Iteration: 340 Training Loss: 0.064\n",
      "Epoch: 8/10 Iteration: 345 Training Loss: 0.068\n",
      "Epoch: 8/10 Iteration: 350 Training Loss: 0.058\n",
      "Value Acc: 0.815\n",
      "Epoch: 8/10 Iteration: 355 Training Loss: 0.060\n",
      "Epoch: 8/10 Iteration: 360 Training Loss: 0.072\n",
      "Epoch: 9/10 Iteration: 365 Training Loss: 0.050\n",
      "Epoch: 9/10 Iteration: 370 Training Loss: 0.058\n",
      "Epoch: 9/10 Iteration: 375 Training Loss: 0.051\n",
      "Value Acc: 0.834\n",
      "Epoch: 9/10 Iteration: 380 Training Loss: 0.051\n",
      "Epoch: 9/10 Iteration: 385 Training Loss: 0.041\n",
      "Epoch: 9/10 Iteration: 390 Training Loss: 0.041\n",
      "Epoch: 9/10 Iteration: 395 Training Loss: 0.048\n",
      "Epoch: 9/10 Iteration: 400 Training Loss: 0.046\n",
      "Value Acc: 0.829\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    for e in range(epochs):\n",
    "        state = sess.run(initial_state)\n",
    "        for ii, (x,y) in enumerate(get_batches(train_x,train_y, batch_size),1):\n",
    "            feed = {inputs_: x,\n",
    "                   labels_: y[:,None],\n",
    "                   keep_prob: 0.5,\n",
    "                   initial_state: state}\n",
    "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
    "            \n",
    "            if iteration%5==0:\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                     \"Iteration: {}\".format(iteration),\n",
    "                     \"Training Loss: {:.3f}\".format(loss))\n",
    "                \n",
    "            if iteration%25==0:\n",
    "                val_acc = []\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                for x,y in get_batches(val_x, val_y, batch_size):\n",
    "                    feed = {inputs_: x,\n",
    "                           labels_: y[:,None],\n",
    "                           keep_prob: 1,\n",
    "                           initial_state: val_state}\n",
    "                    batch_acc, val_state = sess.run([accuracy, final_state],feed_dict=feed)\n",
    "                    val_acc.append(batch_acc)\n",
    "                print(\"Value Acc: {:.3f}\".format(np.mean(val_acc)))\n",
    "            iteration += 1\n",
    "    saver.save(sess, \"checkpoint/sentiment.ckpt\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoint/sentiment.ckpt\n",
      "Test Accuracy: 0.831\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoint'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    for ii, (x,y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
    "        feed = {inputs_: x,\n",
    "               labels_: y[:,None],\n",
    "               keep_prob: 1,\n",
    "               initial_state: test_state}\n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test Accuracy: {:.3f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
